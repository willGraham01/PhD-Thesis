\section{Reformulation of \eqref{eq:SI-WaveEqn} as a Non-Local Quantum Graph Problem}

\tstk{intro stuff}

The two formulations in sections \tstk{VP, FDM and where the formulations were first written down} provide us with two methods by which we can approximate the spectrum of \tstk{wave eqn ref}.
In both of these methods we are forced to handle the interaction between the bulk regions and skeleton in some way; either through the global approximation we use (\tstk{var prob}) or through how we tie the various approximations in the bulk regions and skeleton together (\tstk{FDM}).
The question we ask here is whether we can take this one step further; can we entirely remove the equations in the bulk regions from our formulation, replacing them with a suitable term (or terms) in the equations along the skeleton?
Our objective is to arrive at a quantum graph problem, which are relatively well understood when compared to the measure-theoretic formulation \tstk{ref} that we begun with.
We also expect to see some kind of reward in dimension or complexity reduction, as a quantum graph is ultimately a set of one-dimensional intervals.

\subsection{Reduction to a Quantum Graph Problem} \label{ssec:SI-ToQG}
In order to investigate how we should look to reduce \tstk{wave equation} to a quantum graph problem, we should look at how the behaviour of an eigenfunction in the bulk regions affects the behaviour of said eigenfunction on the skeleton.
We already know that the eigenfunction itself is continuous across the skeleton, so the function values on the boundary of each bulk region coincide with the function values on the skeleton.
Furthermore, we also observe that the normal derivative of the eigenfunction from the adjacent regions affects the behaviour along the skeleton.
So, the question is whether we can express the (traces of the) normal derivatives from the adjacent regions in terms of the values of our function on the skeleton, given that we know \tstk{bulk eqn} is satisfied in each bulk region?
Essentially, we are asking whether we can determine the Neumann data of a function that satisfies \tstk{bulk eqn}, given its Dirichlet values on the boundary.
This draws our attention to the Dirichlet-to-Neumann map for the \tstk{wave? Helmholtz?} equation on $\ddom_i$, which we define as follows.

For each $\ddom_i$ and $\omega^2>0$ \tstk{that is not an eigenvalue of the Dirichlet laplacian!!!}, define the set $D_i$ by
\begin{align*}
	D^i_\omega = \{ \bracs{g,h}\in\gradSob{\partial\ddom_i}{S}\times\ltwo{\partial\ddom_i}{S} \ \vert \
	& \exists v\in\gradgradSob{\ddom_i}{\lambda_2} \text{ s.t. } \\
	&\quad \bracs{\laplacian_\qm + \omega^2}v = 0, \\
	&\quad v\vert_{\partial\ddom_i}=g, \ \left.\bracs{\tgrad v\cdot n}\right\vert_{\partial\ddom_i} = h \}.
	\labelthis\label{eq:SI-DtNMapRegion}
\end{align*}
\tstk{Need the $\tgrad\cdot n$ here, since otherwise we don't satisfy the Green's identity}
The Dirichlet to Neumann map $\dtn^i_\omega$ for the operator $\laplacian_{\qm}+\omega^2$ in the bulk region $\ddom_i$ and $\omega^2$ is then the operator $\dtn^i_\omega$ where
\begin{align*}
	\dom\bracs{\dtn^i_\omega} = D^i_\omega, \qquad
	\dtn^i_\omega g = h,
\end{align*}
where $g,h$ are related as in \eqref{eq:SI-DtNMapRegion}. 
\tstk{We need to be careful that $\omega^2$ is not an eigenvalue of the Dirichlet laplacian - otherwise this definition is anything but well-defined. As such, might be worth checking that an eigenfunction of the Dirichlet laplacian can never be (part of) a solution to our original problem?}
The Dirichlet-to-Neumann (DtN) map will allow us to remove \eqref{eq:SI-BulkEqn} entirely, and replace \eqref{eq:SI-BulkEqn}-\eqref{eq:SI-VertexCondition} with a quantum graph problem.
Indeed, suppose we have a solution $u, \omega^2$ to \eqref{eq:SI-BulkEqn}-\eqref{eq:SI-VertexCondition}.
Then we notice that for every bulk region $\ddom_i$, $u\in\gradSob{\partial\ddom_i}{S}$ and there exists a $v$ as in \eqref{eq:SI-DtNMapRegion} (that $v$ \emph{being} $u$).
Given continuity of $u$ across the skeleton, we thus have that
\begin{align*}
	\bracs{\tgrad u\cdot n_{jk}}^+ = -\bracs{\dtn^+_\omega u}\vert_{I_{jk}},
	&\quad
	\bracs{\tgrad u\cdot n_{jk}}^- = \bracs{\dtn^-_\omega u}\vert_{I_{jk}},
\end{align*}
where we have used $\pm$ to denote the Dirichlet-to-Neumann maps for the regions $\ddom^{\pm}_{jk}$.
Substituting into \eqref{eq:SI-InclusionEqn} gives us the new equation
\begin{align*}
	- \bracs{\diff{}{y} + \rmi\qm_{jk}}^2u^{(jk)} 
	&= \omega^2 u^{(jk)} - \bracs{ \dtn^+_\omega u + \dtn^-_\omega u },
\end{align*}
on each $I_{jk}$.

As such, consider an eigenpair $\omega^2>0, u\in H^2\bracs{\graph}$ of the problem
\begin{subequations} \label{eq:SI-NonLocalQG}
	\begin{align}
		- \bracs{\diff{}{y} + \rmi\qm_{jk}}^2u^{(jk)} 
		&= \omega^2 u^{(jk)} - \bracs{ \dtn^+_\omega u^{(jk)} + \dtn^-_\omega u^{(jk)}},
		&\qquad\text{on } I_{jk}, \label{eq:SI-NonLocalQGEdgeEquation}  \\
		\sum_{j\con k} \bracs{\pdiff{}{n}+\rmi\qm_{jk}} u^{(jk)}(v_j) &= 0,
		&\qquad\text{at every } v_j\in\vertSet, \label{eq:SI-NonLocalQGVertexDeriv} \\
		u \text{ is continuous,} & 
		&\qquad\text{at every } v_j\in\vertSet. \label{eq:SI-NonLocalQGVertexCont}
	\end{align}
\end{subequations}
It can be demonstrated that this eigenpair of \eqref{eq:SI-NonLocalQG} also defines a solution $\omega^2, \tilde{u}$ to \eqref{eq:SI-BulkEqn}-\eqref{eq:SI-VertexCondition}.
Take $\tilde{u}=u$ on $\graph$, and in the bulk regions assign $\tilde{u}$ the values of the function $v$ in \eqref{eq:SI-DtNMapRegion} for $g=u$ (which exists since we assume $u$ solves \eqref{eq:SI-NonLocalQG} in the first place).
Conversely, a solution $\omega^2, \tilde{u}$ to \eqref{eq:SI-BulkEqn}-\eqref{eq:SI-VertexCondition} defines a solution $\omega^2, u$ to \eqref{eq:SI-NonLocalQG} simply by taking $u = \tilde{u}$ on $\graph$. \tstk{$\omega^2$ not on Dirichlet spectrum...}
\tstk{Therefore, \eqref{eq:SI-NonLocalQG} provides us with a new system.... except Dirichlet spectrum, talk about what happens if you're sitting here --- can't say much other than the region effectively ``disappears" and the equations on the skeleton edges that touched the region should be replaced by function equals 0 and continuous normal derivative...}

The problem \eqref{eq:SI-NonLocalQG} is inherently non-local --- notice that (for each edge $I_{jk}$) the terms $\dtn^{\pm}_\omega u$ require information about the function $u$ on edges that form the boundary of one of the adjacent region $\ddom_{jk}^{\pm}$, which are not necessarily (directly) connected to $I_{jk}$ itself.
As such, the price paid to remove \eqref{eq:SI-BulkEqn} from the formulation and move to the purely quantum graph problem \eqref{eq:SI-NonLocalQG} is the introduction of the non-local operator $\dtn^{\pm}_\omega$, which renders our previous approaches via the $M$-matrix (\tstk{chapter ref}) unusable.
This also has implications when we attempt to solve \eqref{eq:SI-NonLocalQG} numerically, which is the subject of \tstk{create this section!}.

\tstk{draw some parallels with QG from bulky vertex part - discussion follows}
The system \eqref{eq:SI-NonLocalQG} has parallels with the system \tstk{ref} - in particular, we remark at how the ODEs on the edges \eqref{eq:SI-NonLocalQGEdgeEquation} depend in a non-standard way on the spectral parameter $\omega^2$.
Most notably, the system \tstk{old system} has $\omega^2$ appearing in the vertex conditions, or to rephrase this, in the \emph{boundary conditions} for the ODEs on the edges $I_{jk}$.
This appearance of $\omega^2$ in the vertex conditions was the direct affect of the measure $\nu$ providing the vertices with some ``size".
In this section, rather than a graph with ``bulky vertices", we instead have a set of regions $\ddom_i$ with ``bulky edges" --- the singular inclusions.
And again, we observe that bestowing a notion of length to our singular inclusions (through $\ddmes$) has caused $\omega^2$ to appear in what would be our boundary conditions for the regions $\ddom_i$, in the form of the terms involving the DtN maps from the adjacent regions in \eqref{eq:SI-NonLocalQGEdgeEquation}.
\tstk{so we're now back in the realm of generalised resolvents? We should now expect the possibility of spectral gaps being opened up. Also, we'll return to this when we talk about Strauss extensions and hypothesise about adding the vertex measure $\nu$ back in.}

\subsection{``Spectral Method" on the Inclusions} \label{ssec:SI-GraphMethod}
\tstk{content of this section summarises \texttt{02-11-21\_NumericalSchemeOnGraphProposal.pdf}. Also, write an appropriate linking introduction here!}

In this section we propose a method for solving \eqref{eq:SI-NonLocalQG} that avoids directly solving the ``Helmholtz-like" PDEs \eqref{eq:SI-BulkEqn} in each of the bulk regions.
The price we pay for this is that our ODEs on each edge now involve the DtN map, which is a non-local operator and requires global knowledge of the function $u$ to evaluate.
This non-locality also rules out a finite difference approach, as we have no way of expressing the action of the DtN map in terms of nearby function values.
Instead, we take a starting point akin to that of ``spectral methods" and finite element methods for solving PDE problems; we will express our solution $u$ in terms of a set of basis functions, and then choose the coefficients of the basis expansion to satisfy the problem \eqref{eq:SI-NonLocalQG} as well as possible.
\tstk{both of these methods do this, but the mentality is different. FEM methods use basis functions that are inherently local, whilst a spectral method will use functions that are nonzero over the whole domain. In practice, we will likely err towards the FEM approach.}
\tstk{Note: if we want to find $u,\omega^2$ simultaneously (that is, actually solve the eigenvalue problem) we just adapt the final form of our numerical scheme).}

Let $V\subset\htwo{\graph}$ be a finite-dimensional subspace with dimension $M$ and basis functions $\clbracs{\psi_m}_{m=1}^{M}$.
Write the approximate solution $u_V\in V$ to \eqref{eq:SI-NonLocalQG} as
\begin{align*}
	u_V &= \sum_{m=1}^M u_m\psi_m, \qquad u_m\in\complex,
\end{align*}
for basis coefficients $u_m$ to be determined.
\tstk{not being near the Dirichlet spectrum of the laplacian is important now!!!!}
The operator $\dtn_{\omega}^i$ is self-adjoint and has compact resolvent (as its inverse is the Neumann to Dirichlet map), and thus possesses a sequence of eigenvalues $\lambda^i_n$ and eigenfunctions $\varphi_n^i$, where we list the $\lambda^i_n$ in ascending order (in $n$, for each $i$).
These eigenfunctions also form a basis of the space $\ltwo{\partial\ddom_i}{S}$, and can be extended by zero to functions $\hat{\varphi}_n^i$ in $L^2\bracs{\graph}$.
This means that we can represent each $\psi_m\vert_{\partial\ddom_i}$ as a sum of the $\varphi_n^i$ as
\begin{align*}
	\psi_m = \sum_{n=1}^{\infty} c_{m,n}^i \varphi_n^i, \quad c_{m,n}^i = \ip{\psi_m}{\varphi_n^i}_{\ltwo{\partial\ddom_i}{S}},
\end{align*}
and each of the $\hat{\varphi}_n^i$ as
\begin{align*}
	\hat{\varphi}_n^i = \sum_{n=1}^{\infty} \hat{c}_{n,m}^i \psi_m, \quad \hat{c}_{n,m}^i = \ip{\varphi_n^i}{\psi_m}_{L^2\bracs{\graph}}.
\end{align*}
Furthermore, extending $\varphi_n^i$ by zero implies that
\begin{align*}
	\hat{c}_{n,m}^i = \ip{\varphi_n^i}{\psi_m}_{L^2\bracs{\graph}} = \ip{\varphi_n^i}{\psi_m}_{\ltwo{\partial\ddom_i}{S}} = \overline{\ip{\psi_m}{\varphi_n^i}}_{\ltwo{\partial\ddom_i}{S}} = \overline{c}_{m,n}^i,
\end{align*}
which cuts down on the number of computations we need to perform.
Choose a ``truncation index" $N_i$ for each $\ddom_i$, and define the matrices $B, C, L$ via
\begin{align*}
	B_{n,m} &= \ip{\tgrad\psi_m}{\tgrad\psi_n}_{L^2\bracs{\graph}}, \\
	C_{n,m} &= \ip{\psi_m}{\psi_n}_{L^2\bracs{\graph}}, \\
	L_{n,m} &= \sum_{v_j\in\vertSet}\sum_{j\conLeft k}
	\sqbracs{ \sum_{p=1}^{N_+}c_{m,p}^+\lambda^+_p \sum_{q=1}^M \hat{c}_{p,q}^+ \ip{\psi_q}{\psi_n}_{L^2\bracs{I_{jk}}} + \sum_{p=1}^{N_-}c_{m,p}^-\lambda^-_p \sum_{q=1}^M \hat{c}_{p,q}^- \ip{\psi_q}{\psi_n}_{L^2\bracs{I_{jk}}} },
\end{align*}
where we use our usual $\pm$ notation for the regions $\ddom^{\pm}$ adjacent to an edge $I_{jk}$.
\tstk{include this derivation in an appendix? It's long but straightforward}
\tstk{the sum is not as daunting as it seems if we are clever with our choice of $\psi_m$ --- notably, if we take local basis functions (hats or tents) then the majority of the coefficients are zero, and }
Setting $U = \bracs{u_1, ..., u_M}^\top$, our approximate solution $u_V$ can then be found by determining the solution to
\begin{align*}
	B U &= \bracs{\omega^2 C - L} U.
\end{align*}
Note that $B$ is the term in the above equation which does not depend on $\omega^2$ --- $L$ depends on $\omega^2$ through the eigenfunctions associated to the DtN map of the ``Helmholtz" operator $\laplacian_{\qm}+\omega^2$.
This provides us with a system of $M$ algebraic equations in $M$ unknowns which we can solve for $U$, or if $\omega^2$ is unknown, we can solve as a generalised eigenvalue problem.
However, at each step of the generalised eigenvalue problem, we will need to compute $L_{n,m}$ again, since $\omega$ will be iteratively updated, which in turn will require us to compute new eigenfunctions.
\tstk{Note that, if we are interested in the resolvent equation (replace $\omega^2 u$ with $f$ in the original formulation) then we just replace $\omega^2 C$ with the column vector $F=\bracs{f_1,...,f_M}^\top$ where $f = \sum_{m=1}^M f_m\psi_m$.}
Additionally, this method also requires us to know the $\lambda_n^i, \varphi_n^i$ a priori, or to have available a method for obtaining them, which we discuss in \tstk{section}.

\subsubsection{Computing the DtN eigenvalues and eigenfunctions} \label{sssec:ComputingDtNEfuncs}
We can compute the DtN operator's eigenvalues (and eigenfunctions) via the ``max-min" principle;
\begin{align*}
	\lambda^i_n &= \max_{S_{n-1}}\min_{\varphi\in S_{n-1}}\clbracs{ \frac{\ip{\varphi}{\dtn_{\omega}^i\varphi}_{\ltwo{\partial\ddom_i}{S}}}{\norm{\varphi}_{\ltwo{\partial\ddom_i}{S}}} \setVert \varphi\perp S_{n-1}},
\end{align*}
where $S_{n-1}$ is a subspace of $\ltwo{\partial\ddom_i}{S}$ with dimension $n-1$.
The eigenfunction $\varphi_n^i$ associated with $\lambda^i_n$ is the $\varphi$ for which the ``max-min" is attained.
Given the domain of $\dtn_{\omega}^i$, observe that
\begin{align*}
	\ip{\varphi}{\dtn_{\omega}^i\varphi}_{\ltwo{\partial\ddom_i}{S}}
	&= \integral{\ddom_i}{ \tgrad \varphi\cdot\overline{\tgrad \varphi} + \varphi\overline{\laplacian_{\qm} \varphi} }{x} \\
	&= \integral{\ddom_i}{ \tgrad \varphi\cdot\overline{\tgrad \varphi} - \omega^2 \varphi\overline{\varphi} }{x}
	= \norm{\tgrad \varphi}_{\ltwo{\ddom_i}{x}} - \omega^2 \norm{\varphi}_{\ltwo{\ddom_i}{x}},
\end{align*}
and therefore
\begin{align*}
	\lambda^i_n 
	&= \max_{S'_{n-1}}\min_{\varphi\in S'_{n-1}}\clbracs{ \frac{\norm{\tgrad \varphi}_{\ltwo{\ddom_i}{x}} - \omega^2 \norm{\varphi}_{\ltwo{\ddom_i}{x}}}{\norm{\varphi}_{\ltwo{\partial\ddom_i}{S}}} \setVert \varphi\perp S'_{n-1} }, \\
	&= \max_{S'_{n-1}}\min_{\varphi\in S'_{n-1}}\clbracs{ \norm{\tgrad \varphi}_{\ltwo{\ddom_i}{x}} - \omega^2 \norm{\varphi}_{\ltwo{\ddom_i}{x}} \setVert \norm{\varphi}_{\ltwo{\partial\ddom_i}{S}}=1, \ \varphi\perp S'_{n-1} },
\end{align*}
\tstk{does this exist as our objective function doesn't have to behave nicely right? This is also tied to us having to avoid any eigenvalues of the dirichlet laplacian}
where $S'_{n-1}$ is a subspace of $\gradgradSob{\ddom_i}{\lambda_2}$ with dimension $n-1$.
We then have the following procedure available to extract the $\lambda_n^i, \varphi_n^i$:
\begin{enumerate}
	\item Solve
	\begin{align*}
		\lambda_1^i &= \min_{\substack{\varphi\in\gradgradSob{\ddom_i}{\lambda_2} \\ \norm{\varphi}_{\ltwo{\partial\ddom_i}{S}}=1}} \clbracs{ \norm{\tgrad \varphi}_{\ltwo{\ddom_i}{x}} - \omega^2 \norm{\varphi}_{\ltwo{\ddom_i}{x}} },
	\end{align*}
	to obtain $\lambda_1^i$.
	The argmin of the above expression is the eigenfunction $\varphi_1^i$.
	\item For $n>1$, the eigenfunctions $\varphi_k^i$ are known for $1\leq k\leq n-1$.
	Furthermore, we also know that $\varphi_n^i$ is orthogonal to each of the $\varphi_k^i$, and so we know that the subspace in which the maximum will be attained is $S'_{n-1} = \mathrm{span}\clbracs{\varphi_k^i \setVert 1\leq k\leq n-1}$.
	Thus, we solve
	\begin{align*}
		\lambda_n^i &= \min_{\substack{\varphi\in\gradgradSob{\ddom_i}{\lambda_2} \\ \norm{\varphi}_{\ltwo{\partial\ddom_i}{S}}=1}} \clbracs{ \norm{\tgrad \varphi}_{\ltwo{\ddom_i}{x}} - \omega^2 \norm{\varphi}_{\ltwo{\ddom_i}{x}} \setVert \varphi\perp\varphi_k^i, \text{ for each } 1\leq k\leq n-1 },
	\end{align*}
	with the argmin being the eigenfunction $\varphi_n^i$.
\end{enumerate}
We can numerically solve these minimisation problems via the method of Lagrange multipliers for example, but this would require us to settle for approximate $\varphi_n^i$ and eigenvalues.

\section*{HYPOTHETICALS: Theory Needed, and Cost Estimations/ Summary}
We summarise here the overall algorithm that we are proposing and where the largest ``computational costs" will come from.

The procedure is as follows:
\begin{enumerate}
	\item Choose a finite-dimensional subspace $V\subset\gradgradSob{\graph}{\lambda_2}$ and a basis $\clbracs{\psi_m}_{m=1}^M$.
	Recommend a basis of locally-defined functions, like ``tent" or ``hat" functions placed on nodes along the edges of $\graph$.
	\item For each region $i$, compute the first $N_i$ eigenvalues $\lambda_n^i$ and eigenfunctions $\varphi_n^i$ for the map $\dtn_{\omega}^i$.
	The choice of $N_i$ will be important here --- too high might lead to heavy computational cost, whilst too small might lead to inaccuracy.
	A happy medium might n\"iavely seem to be choosing $N_i = M$ for every region, given that we are already working in a finite dimensional subspace for $u$, its shouldn't hurt to throw away the higher eigenvalues, but having less than $M$ might cause issues for the change of basis calculations.
	\item Compute the coefficients $c_{m,n}^i$ and the entries of the matrices $B, C, L$.
	The entries of $B$ and $C$ can be computed immediately after step 1, or analytically to save on numerical approximation of integrals.
	It is also worth noting that $c_{m,n}^i=0$ whenever $\supp\bracs{\psi_m}\cap\partial\ddom_i = \emptyset$, and that $\hat{c}_{m,n}^i=\overline{c}_{n,m}^i$.
	\item Solve the system $B U = \bracs{\omega^2 C - L} U$.
	Note that if we are solving for $\omega^2$ and $u_V$, $L$ will need to be recomputed at each iteration of the solve.
	Also, $B, C$, and $L$ are Hermitian, as can be seen from their (and the basis coefficients') definitions in terms of inner products.
\end{enumerate}

The key idea here is that $B,C$ only need to be computed once, and are only $M\times M$ in size (although will in general be dense matrices).
The two \emph{major} costs will come in from steps 2 and 4:
\begin{itemize}
	\item Step 4 requires a matrix solve.
	If we are using $\omega$ as a constant, or are looking at the resolvent problem, then this cost is that of solving an $M\times M$ system.
	If however we are trying to find $\omega^2$ and $u_V$, then this cost is multiplied by the cost of computing the Steklov functions in step 2.
	\item Step 2 requires us to determine the first $N_i$ of the DtN eigenfunctions (and eigenvalues), by solving $N_i$ constrained optimisation problems.
	We also have to introduce a finite dimensional space $W\subset\gradgradSob{\ddom_i}{\lambda_2}$ to approximate the $\varphi_n^i$ in, which will affect the accuracy of the approximate solution $u_V$.
	Let $W$ have dimension $p$ for the cost estimation that follows.
	The cost for each optimisation problem should be of the order of another linear-system solve, but I'll need to double check.
\end{itemize}
Thus, I estimate the (major) cost of the numerical scheme to be (worst case, assuming we want to find $\omega^2$ too);
\begin{align*}
	\text{ cost } 
	&= \bracs{ M\times M \text{ eigenvalue or linear system solve} } \\
	& \quad\times \sum_{N_i}\bracs{ N_i \times (p\times p-\text{constrained optimisation problem solves}) }.
\end{align*}
The memory usage would be of the order of (worst case, assuming no $c_{m,n}^i$ are zero)
\begin{align*}
	\text{ memory }
	&= (M+1)\sum_{i}N_i  &\qquad\text{for the } c_{m,n}^i \text{ and } \lambda_n^i, \\
	& \ + 3M^2 &\qquad\text{for the entries of } B, C, L, \\
	& \ + M^2\abs{\edgeSet} &\qquad\text{for each } \ip{\psi_q}{\psi_n}_{L^2\bracs{I_{jk}}},
\end{align*}
so would be of the order $M^2$ if we are choosing $N_i$ of the order $M$.
There is also a memory cost accrued for the representation of the solution to each optimisation problem for the $\lambda_n^i$, however once we are done with computing the $\lambda_n^i$ for the region $\ddom_i$, we can compute any associated $c_{m,n}^i$ and then reuse the memory assigned to the representations.

The theory that would then need to be filled in or investigated would be
\begin{itemize}
	\item Assurance that $u_V$ gets close to $u$ as the dimension of $V$ increases, or at least is optimal in $V$ (cf Cea's lemma).
	\item The accuracy loss from truncation at $N_i$.
	\item Accuracy loss from the representation of the $\varphi_n^i$.
	\item Optimal (or necessary) conditions on $N_i$ and $p$ given $M$.
	\item Any timesaves that we can make computationally or analytically --- for example, identical $\ddom_i$ have identical eigenfunctions (computational), and we can compute some of the inner products if we choose our $\psi_m$ cleverly (analytical).
\end{itemize}